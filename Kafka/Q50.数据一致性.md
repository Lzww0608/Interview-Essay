# Q50.数据一致性

Kafka的数据一致性原理主要通过以下三个方面实现：

1. **副本机制**：Kafka将每个主题分成多个分区，并将每个分区的数据副本保存在多个服务器上。这样，当某个服务器故障时，仍然可以从其他服务器获取数据，从而保证数据的可靠性。
2. **ISR（In-Sync Replicas）机制**：Kafka中有一个特殊的副本集合，称为ISR。ISR中的副本与主副本同步，即它们的数据是一致的。当一个分区的某个副本与主副本不同步时，它会被从ISR中移除，直到与主副本同步后再重新加入。这个机制可以保证数据的一致性。
3. **选举机制**：Kafka中有一个选举机制，用于选择一个ISR中的副本作为新的主副本，以保证数据的可靠性。当主副本故障时，Kafka会从ISR中选择一个副本作为新的主副本，并将其他副本同步到新的主副本上。

此外，Kafka还通过HW（High Water Mark）机制来保证数据的一致性。当follower故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。

综上所述，Kafka通过分区副本、ISR机制、选举机制以及HW机制来保证数据的一致性。