# Q95. Kafka如何保证消息不丢失

Kafka为了保证消息不丢失，采用了多种技术和配置来增强消息的持久化和可靠性。以下是一系列Kafka为保证消息不丢失而采取的措施：

1. **持久化存储**：
   - Kafka将所有发布的消息持久化存储在磁盘上，而不是仅仅在内存中缓存。消息会被写入到日志文件中，这部分日志文件是落地存储的，即使服务器重启，消息也不会丢失。
2. **副本和ISR（In-Sync Replicas）机制**：
   - Kafka的主题可以配置多个副本（partitions的副本），每个partition至少有一个Leader副本，其他副本是Follower副本。
   - Leader副本负责处理读写请求，Follower副本会不断从Leader同步数据，形成一个同步的ISR集合。
   - 在配置了合适的消息复制因子（replication.factor）后，只要 ISR 集合中的至少一个副本存活，就可以保证消息不丢失。
3. **异步复制和同步提交**：
   - 默认情况下，Kafka producer在发送消息时可以选择异步或同步方式。如果想要确保消息不丢失，可以将`acks`参数设置为`all`或`-1`，这样只有当所有ISR副本都接收到消息后，Kafka才会向producer返回确认信息。
4. **幂等性（Idempotence）**：
   - Kafka 0.11版本开始支持producer的幂等性，开启后，即使由于网络问题导致producer重试发送消息，Kafka也能确保每条消息只被存储一次，不会出现重复消息。
5. **日志刷盘策略**：
   - Kafka可以配置日志刷盘策略，例如`acks=all`和`flush.ms`、`linger.ms`等参数组合，确保数据尽可能快地从缓存刷入磁盘。
6. **监控和运维**：
   - 维护良好的Kafka集群健康状况，包括监控节点健康、确保磁盘空间足够、合理设置日志清理策略（log.retention.hours、log.segment.bytes等）等，也可以间接防止消息丢失。