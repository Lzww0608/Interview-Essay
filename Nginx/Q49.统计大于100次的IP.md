# Q49.统计大于100次的IP

要分析Nginx日志并统计访问次数超过100次的IP地址，你可以使用Unix/Linux命令行工具如`awk`、`sort`、`uniq`等来处理Nginx的访问日志文件。以下是一个使用这些工具的基本步骤，这将帮助你找到那些访问次数超过100次的IP地址。

#### 步骤

1. **使用`awk`提取IP地址**：首先，从Nginx日志中提取每一行的IP地址。通常，IP地址位于日志行的开头。
2. **使用sort和uniq统计每个IP的访问次数**：然后，对提取的IP地址进行排序，并使用`uniq -c`来统计每个IP地址的出现次数。
3. **使用awk过滤出访问次数超过100次的IP地址**：最后，利用`awk`命令过滤出那些访问次数超过100次的IP地址。

#### 示例命令

假设你的Nginx访问日志文件位于`/var/log/nginx/access.log`，你可以运行以下命令：

```sh
awk '{print 1}' /var/log/nginx/access.log | sort | uniq -c | sort -nr | awk '1 > 100'
```

#### 命令解释

- `awk '{print $1}' /var/log/nginx/access.log`：提取日志中的每行的第一个字段（IP地址）。
- `sort`：将IP地址排序，以便`uniq`能正确统计。
- `uniq -c`：统计每个IP地址的出现次数。
- `sort -nr`：对结果进行数值降序排序，以便最频繁的访问者排在最前面。
- `awk '$1 > 100'`：过滤出访问次数超过100次的记录。

#### 注意事项

- 上述命令假设IP地址位于Nginx日志行的第一个字段。如果你的日志格式不同，可能需要调整`awk '{print $1}'`中的`$1`以匹配正确的字段。
- 由于日志文件可能非常大，这个命令可能需要一些时间来执行。